{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "TdZ4bdOAE-KP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# class for Predicate\n",
        "\n",
        "class Predicate:\n",
        "    def __init__(self, ident, nm, deg):\n",
        "        self.id = ident # identifier of the predicate\n",
        "        self.name = nm  # Name of the predicate\n",
        "        self.degree = deg  # RENAME IT to (degree)\n",
        "        #self.predicateTerms = [] #\n",
        "        self.rules = None   # To add a rule to the list that uses the predicate\n",
        "\n",
        "    def getPredicateID(self):\n",
        "        return self.id\n",
        "\n",
        "    def getPredicateName(self):\n",
        "        return self.name\n",
        "    # should be getPredicateDegree\n",
        "    def getPredicateDegree(self):\n",
        "        return self.degree\n",
        "\n",
        "    #def addPredicateTerms(self, term: str):\n",
        "     #   self.predicateTerms.append(term)\n",
        "\n",
        "    #def getPredicateTerms(self):\n",
        "    #    return self.predicateTerms\n",
        "\n",
        "    def getPredicateRules(self):\n",
        "        return self.rules\n",
        "\n",
        "    #def setPredicateRules(self, rls):\n",
        "     #   self.rules = rls\n",
        "\n",
        "    def addPredicateRule(self, rle):\n",
        "        if self.rules is None:\n",
        "            self.rules = [rle]\n",
        "        else:\n",
        "            if rle not in self.rules:\n",
        "                self.rules.append(rle)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"[ID, NAME] = [{self.id}, {self.name}]\\n\"\n",
        "\n",
        "## class for Rules\n",
        "\n",
        "\n",
        "class Rule:\n",
        "    def __init__(self, ruleID: int):\n",
        "        self.ruleID = ruleID    # rule Id\n",
        "        self.ruleBodyPredicates = [] # provide list of predicates that are used in the rule\n",
        "        self.ruleExistentialVariables = {}  # a dictionary of Predicates as key, and variable as value\n",
        "        self.ruleConclusions = []   # provide the list of the predicates used in the conclusion\n",
        "        self.ruleConclusionVariables = {}\n",
        "\n",
        "    def getRuleID(self):\n",
        "        return self.ruleID\n",
        "\n",
        "    def addRuleBodyPredicates(self, predicate: str):\n",
        "        self.ruleBodyPredicates.append(predicate)\n",
        "\n",
        "    def getRuleBodyPredicatesSize(self):\n",
        "        return len(self.ruleBodyPredicates)\n",
        "\n",
        "    def getRuleBodyPredicates(self):\n",
        "        return self.ruleBodyPredicates\n",
        "\n",
        "    def addRuleExistentialVariable(self, predi ,variable):\n",
        "        self.ruleExistentialVariables[predi] = variable\n",
        "\n",
        "    def getRuleExistentialVariables(self):\n",
        "        if len(self.ruleExistentialVariables) == 0:\n",
        "            return None\n",
        "        return self.ruleExistentialVariables\n",
        "\n",
        "    def addRuleConclusion(self, conclusion: str):\n",
        "        self.ruleConclusions.append(conclusion)\n",
        "\n",
        "    def getRuleConclusions(self):\n",
        "        return self.ruleConclusions\n",
        "\n",
        "    def addRuleConclusionVariables(self, predi ,variable):\n",
        "        self.ruleConclusionVariables[predi] = variable\n",
        "\n",
        "    def getRuleConclusionVariables(self):\n",
        "        if len(self.ruleConclusionVariables) == 0:\n",
        "            return None\n",
        "        return self.ruleConclusionVariables\n",
        "\n",
        "## Context definition\n",
        "\n",
        "class Context:\n",
        "    def __init__(self, contextID: int):\n",
        "        self.contextID = contextID      # Context Id\n",
        "        self.contextExistentialRules = set()        # provide a set of rules that are inside the context\n",
        "        self.contextLabel = None      # provide the body predicates of the rules inside the context\n",
        "        self.ruleSize = []            # size of the body of the rules in context\n",
        "        self.conclusions = []\n",
        "\n",
        "    def getContextID(self):\n",
        "        return self.contextID\n",
        "\n",
        "    def addContextExistentialRule(self, rule: str):\n",
        "        self.contextExistentialRules.add(rule)\n",
        "\n",
        "    def addRuleBodySize(self, i):\n",
        "        self.ruleSize.append(i)\n",
        "\n",
        "    def getRuleBodySize(self):\n",
        "        return self.ruleSize\n",
        "\n",
        "    def getContextExistentialRules(self):\n",
        "        if len(self.contextExistentialRules) == 0:\n",
        "            return None\n",
        "        return self.contextExistentialRules\n",
        "\n",
        "    def addContextLabel(self, label):\n",
        "        if self.contextLabel is None:\n",
        "            self.contextLabel = [label]\n",
        "        else:\n",
        "            if label not in self.contextLabel:\n",
        "               self.contextLabel.append(label)\n",
        "\n",
        "    def getContextLabel(self):\n",
        "        return self.contextLabel\n",
        "\n",
        "    def addContextConclusions(self, conclusion):\n",
        "        self.conclusions.append(conclusion)\n",
        "\n",
        "    def getContextConclusions(self):\n",
        "        return self.conclusions\n",
        "\n",
        "# class Facts\n",
        "\n",
        "class Fact:\n",
        "    def __init__(self, ident):\n",
        "        self.id = ident         #fact id\n",
        "        self.constant = []      # list of constants for fact\n",
        "        self.terms = []         #list of predicates of fact --> this is not the terms, name it Predicate\n",
        "        self.facts = {}         # dict providing predicates as key and const as values\n",
        "\n",
        "    def getFactId(self):\n",
        "        return self.id\n",
        "\n",
        "    def addFacts(self, pred, const):\n",
        "        self.facts[pred] = const\n",
        "\n",
        "    def getFacts(self):\n",
        "        return self.facts\n",
        "\n",
        "    def addFactTerms(self, predicate: str):\n",
        "        self.terms.append(predicate)\n",
        "\n",
        "    def addFactConstant(self, const):\n",
        "        self.constant.append(const)\n",
        "\n",
        "    def getFactTerms(self):\n",
        "        return self.terms\n",
        "\n",
        "    def getFactConstant(self):\n",
        "        return self.constant\n",
        "\n",
        "    def __del__(self):\n",
        "        del self.terms\n",
        "\n",
        "\n",
        "\n",
        "##Partitioned Facts\n",
        "\n",
        "class PartitionedFact:\n",
        "    def __init__(self, id):\n",
        "        self.id = id        #id for the partitioned fact, normally set as the id of context matched\n",
        "        self.Facts = []     #list of the facts added\n",
        "\n",
        "    def getID(self):\n",
        "        return self.id\n",
        "\n",
        "    def addFacts(self, fact):\n",
        "        self.Facts.append(fact)\n",
        "\n",
        "    def getPartitionedFacts(self):\n",
        "        return self.Facts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Ym8-HBzsFARd"
      },
      "outputs": [],
      "source": [
        "################# Predicates ################\n",
        "Animal = Predicate(1, 'Animal', 1)\n",
        "Vertebrates = Predicate(2, 'Vertebrates', 1)\n",
        "Mammal = Predicate(3, 'Mammal', 1)\n",
        "hasPart = Predicate(4, 'hasPart', 2)\n",
        "hasPart_Mammal = Predicate(7, 'hasPart_Mammal', 1)\n",
        "hasPart_Hair = Predicate(8, 'hasPart_Hair', 1)\n",
        "hasPart_Bone = Predicate(9, 'hasPart_Bone', 1)\n",
        "Skeleton = Predicate(5, 'Skeleton', 1)\n",
        "Ostiechtyien = Predicate(6, 'Ostiechtyien', 1)\n",
        "alert = Predicate(7, 'alert', 1)\n",
        "set_predicates = set()\n",
        "set_predicates.add(Animal)\n",
        "set_predicates.add(Vertebrates)\n",
        "set_predicates.add(Mammal)\n",
        "set_predicates.add(hasPart)\n",
        "set_predicates.add(hasPart_Mammal)\n",
        "set_predicates.add(hasPart_Hair)\n",
        "set_predicates.add(hasPart_Bone)\n",
        "set_predicates.add(Skeleton)\n",
        "set_predicates.add(Ostiechtyien)\n",
        "set_predicates.add(alert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtIZP2Y7FUGz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "gh1AKAlcFXWy"
      },
      "outputs": [],
      "source": [
        "############ Facts ###############\n",
        "FactAnimal = Fact(1)\n",
        "#FactHasPart = Fact(2)\n",
        "FactHasPart_Hair = Fact(2)\n",
        "#FactHasPart_Mammal = Fact(4)\n",
        "\n",
        "FactAnimal.addFactConstant('Cats')\n",
        "FactAnimal.addFactConstant('Dogs')\n",
        "FactAnimal.addFactConstant('Mice')\n",
        "FactAnimal.addFactConstant('Camels')\n",
        "FactAnimal.addFactTerms(Animal.getPredicateName())\n",
        "\n",
        "FactHasPart_Hair.addFactConstant('Mice')\n",
        "FactHasPart_Hair.addFactConstant('Dog')\n",
        "FactHasPart_Hair.addFactConstant('Cats')\n",
        "FactHasPart_Hair.addFactConstant('Camels')\n",
        "FactHasPart_Hair.addFactTerms(hasPart_Hair.getPredicateName())\n",
        "\n",
        "#FactHasPart.addFactConstant(('Mice', 'hair'))\n",
        "#FactHasPart.addFactConstant(('Dogs', 'hair'))\n",
        "#FactHasPart.addFactConstant(('Cats', 'hair'))\n",
        "#FactHasPart.addFactConstant(('Camels', 'hair'))\n",
        "#FactHasPart.addFactTerms(hasPart.getPredicateName())\n",
        "\n",
        "\n",
        "FactAnimal.addFacts(Animal.getPredicateName(), ['Cats', 'Dogs', 'Mice', 'Camels'])\n",
        "FactHasPart_Hair.addFacts(hasPart_Hair.getPredicateName(), ['Mice', 'Dogs', 'Cats', 'Camels'])\n",
        "\n",
        "\n",
        "set_facts = set()\n",
        "\n",
        "set_facts.add(FactAnimal)\n",
        "set_facts.add(FactHasPart_Hair)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "uPXtRTkQFe4q"
      },
      "outputs": [],
      "source": [
        "rule1 = Rule(1)\n",
        "rule2 = Rule(2)\n",
        "rule3 = Rule(3)\n",
        "rule4 = Rule(4)\n",
        "rule5 = Rule(5)\n",
        "rule6 = Rule(6)\n",
        "\n",
        "##Rule 1 Body###\n",
        "rule1.addRuleBodyPredicates(Animal.getPredicateName())\n",
        "rule1.addRuleBodyPredicates(hasPart.getPredicateName())\n",
        "rule1.addRuleBodyPredicates(Skeleton.getPredicateName())\n",
        "\n",
        "rule1.addRuleExistentialVariable(Animal.getPredicateName(),'x')\n",
        "rule1.addRuleExistentialVariable(Skeleton.getPredicateName() ,'y')\n",
        "rule1.addRuleExistentialVariable(hasPart.getPredicateName() ,('x','y'))\n",
        "## Rule 1 Conclusion###\n",
        "rule1.addRuleConclusion(Vertebrates.getPredicateName())\n",
        "rule1.addRuleConclusionVariables(Vertebrates.getPredicateName(), 'x')\n",
        "\n",
        "\n",
        "\n",
        "##Rule 2 Body###\n",
        "rule2.addRuleBodyPredicates(Vertebrates.getPredicateName())\n",
        "\n",
        "rule2.addRuleExistentialVariable(Vertebrates.getPredicateName() ,'x')\n",
        "## Rule 2 Conclusion###\n",
        "rule2.addRuleConclusion(Animal.getPredicateName())\n",
        "rule2.addRuleConclusion(hasPart.getPredicateName())\n",
        "rule2.addRuleConclusion(Skeleton.getPredicateName())\n",
        "\n",
        "rule2.addRuleConclusionVariables(Animal.getPredicateName(),'x')\n",
        "rule2.addRuleConclusionVariables(Skeleton.getPredicateName() ,'y')\n",
        "rule2.addRuleConclusionVariables(hasPart.getPredicateName() ,('x','y'))\n",
        "\n",
        "### Rule 3 Bdoy###\n",
        "rule3.addRuleBodyPredicates(Ostiechtyien.getPredicateName())\n",
        "\n",
        "rule3.addRuleExistentialVariable(Ostiechtyien.getPredicateName() ,'x')\n",
        "### Rule 3 conclusion####\n",
        "rule3.addRuleConclusion(Animal.getPredicateName())\n",
        "rule3.addRuleConclusion(hasPart_Bone.getPredicateName())\n",
        "\n",
        "rule3.addRuleConclusionVariables(Animal.getPredicateName() ,'x')\n",
        "rule3.addRuleConclusionVariables(hasPart_Bone.getPredicateName() ,'x')\n",
        "\n",
        "### Rule 4 body###      ### ATTACK###\n",
        "rule4.addRuleBodyPredicates(Mammal.getPredicateName())\n",
        "\n",
        "rule4.addRuleExistentialVariable(Mammal.getPredicateName() ,'x')\n",
        "## Rule 4 conclusion###\n",
        "rule4.addRuleConclusion(alert.getPredicateName())\n",
        "rule4.addRuleConclusionVariables(alert.getPredicateName(), 'x')\n",
        "#rule4.addRuleConclusion(Animal.getPredicateName())\n",
        "#rule4.addRuleConclusion(hasPart_Hair.getPredicateName())\n",
        "\n",
        "#rule4.addRuleConclusionVariables(Animal.getPredicateName() ,'x')\n",
        "#rule4.addRuleConclusionVariables(hasPart_Hair.getPredicateName() ,'x')\n",
        "\n",
        "### Rule 5 body###\n",
        "rule5.addRuleBodyPredicates(Mammal.getPredicateName())\n",
        "\n",
        "rule5.addRuleExistentialVariable(Mammal.getPredicateName() ,'x')\n",
        "## Rule 5 conclusion###\n",
        "rule5.addRuleConclusion(Animal.getPredicateName())\n",
        "rule5.addRuleConclusion(hasPart_Mammal.getPredicateName())\n",
        "\n",
        "rule5.addRuleConclusionVariables(Animal.getPredicateName() ,'x')\n",
        "rule5.addRuleConclusionVariables(hasPart_Mammal.getPredicateName() ,'x')\n",
        "\n",
        "### Rule 6 Body##\n",
        "rule6.addRuleBodyPredicates(Animal.getPredicateName())\n",
        "rule6.addRuleBodyPredicates(hasPart_Hair.getPredicateName())\n",
        "\n",
        "rule6.addRuleExistentialVariable(Animal.getPredicateName() ,'x')\n",
        "rule6.addRuleExistentialVariable(hasPart_Hair.getPredicateName() ,'x')\n",
        "### Rule 6 Conclusion ###\n",
        "rule6.addRuleConclusion(Mammal.getPredicateName())\n",
        "rule6.addRuleConclusionVariables(Mammal.getPredicateName() ,'x')\n",
        "\n",
        "\n",
        "\n",
        "set_rules = set()\n",
        "\n",
        "set_rules.add(rule1)\n",
        "set_rules.add(rule2)\n",
        "set_rules.add(rule3)\n",
        "set_rules.add(rule4)\n",
        "set_rules.add(rule5)\n",
        "set_rules.add(rule6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "############ Facts ###############\n",
        "FactAnimal = Fact(1)\n",
        "#FactHasPart = Fact(2)\n",
        "FactHasPart_Hair = Fact(2)\n",
        "#FactHasPart_Mammal = Fact(4)\n",
        "\n",
        "FactAnimal.addFactConstant('Cats')\n",
        "FactAnimal.addFactConstant('Dogs')\n",
        "FactAnimal.addFactConstant('Mice')\n",
        "FactAnimal.addFactConstant('Camels')\n",
        "FactAnimal.addFactTerms(Animal.getPredicateName())\n",
        "\n",
        "FactHasPart_Hair.addFactConstant('Mice')\n",
        "FactHasPart_Hair.addFactConstant('Dog')\n",
        "FactHasPart_Hair.addFactConstant('Cats')\n",
        "FactHasPart_Hair.addFactConstant('Camels')\n",
        "FactHasPart_Hair.addFactTerms(hasPart_Hair.getPredicateName())\n",
        "\n",
        "#FactHasPart.addFactConstant(('Mice', 'hair'))\n",
        "#FactHasPart.addFactConstant(('Dogs', 'hair'))\n",
        "#FactHasPart.addFactConstant(('Cats', 'hair'))\n",
        "#FactHasPart.addFactConstant(('Camels', 'hair'))\n",
        "#FactHasPart.addFactTerms(hasPart.getPredicateName())\n",
        "\n",
        "\n",
        "FactAnimal.addFacts(Animal.getPredicateName(), ['Cats', 'Dogs', 'Mice', 'Camels'])\n",
        "FactHasPart_Hair.addFacts(hasPart_Hair.getPredicateName(), ['Mice', 'Dogs', 'Cats', 'Camels'])\n",
        "\n",
        "\n",
        "set_facts = set()\n",
        "\n",
        "set_facts.add(FactAnimal)\n",
        "set_facts.add(FactHasPart_Hair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "QuynHaCAFgi2"
      },
      "outputs": [],
      "source": [
        "### Adding rules to the Predicates\n",
        "\n",
        "Animal.addPredicateRule(rule1)\n",
        "hasPart.addPredicateRule(rule1)\n",
        "Skeleton.addPredicateRule(rule1)\n",
        "Vertebrates.addPredicateRule(rule1)\n",
        "\n",
        "\n",
        "Animal.addPredicateRule(rule2)\n",
        "hasPart.addPredicateRule(rule2)\n",
        "Skeleton.addPredicateRule(rule2)\n",
        "Vertebrates.addPredicateRule(rule2)\n",
        "\n",
        "Ostiechtyien.addPredicateRule(rule3)\n",
        "Animal.addPredicateRule(rule3)\n",
        "hasPart_Bone.addPredicateRule(rule3)\n",
        "\n",
        "Mammal.addPredicateRule(rule4)\n",
        "Animal.addPredicateRule(rule4)\n",
        "hasPart_Hair.addPredicateRule(rule4)\n",
        "\n",
        "Mammal.addPredicateRule(rule5)\n",
        "Animal.addPredicateRule(rule5)\n",
        "hasPart_Mammal.addPredicateRule(rule5)\n",
        "\n",
        "Mammal.addPredicateRule(rule6)\n",
        "Animal.addPredicateRule(rule6)\n",
        "hasPart_Hair.addPredicateRule(rule6)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "tGXbd47cDLsh"
      },
      "outputs": [],
      "source": [
        "negative_rules_set = set()\n",
        "def negative_rules(rules)->set:\n",
        "  for r in rules.copy():\n",
        "    Con = r.getRuleConclusions()\n",
        "    if 'alert' in Con:\n",
        "      rules.remove(r)\n",
        "      negative_rules_set.add(r)\n",
        "  return negative_rules_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "negative_rules(set_rules)\n",
        "print(len(negative_rules_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BSdgUeobCfge"
      },
      "outputs": [],
      "source": [
        "def contextMaking(rules):\n",
        "    C = set()\n",
        "    for i in rules:\n",
        "        result = []\n",
        "        if len(C) == 0:\n",
        "            cont = Context(0)\n",
        "            cont.addContextExistentialRule(i)\n",
        "            cont.addRuleBodySize(i.getRuleBodyPredicatesSize())\n",
        "            cont.addContextConclusions(i.getRuleConclusions())\n",
        "            for j in i.getRuleBodyPredicates():\n",
        "                cont.addContextLabel(j)\n",
        "            C.add(cont)\n",
        "        else:\n",
        "            for c in C:\n",
        "                label = set(c.getContextLabel())\n",
        "                res = label.intersection(set(i.getRuleBodyPredicates()))\n",
        "                if len(res) != 0:\n",
        "                    result.append(res)\n",
        "                    cxt = c\n",
        "            if len(result) == 0:\n",
        "                cont = Context(len(C))\n",
        "                cont.addContextExistentialRule(i)\n",
        "                cont.addRuleBodySize(i.getRuleBodyPredicatesSize())\n",
        "                cont.addContextConclusions(i.getRuleConclusions())\n",
        "                for j in i.getRuleBodyPredicates():\n",
        "                    cont.addContextLabel(j)\n",
        "                C.add(cont)\n",
        "            else:\n",
        "                cxt.addContextExistentialRule(i)\n",
        "                for j in i.getRuleBodyPredicates():\n",
        "                    cxt.addContextLabel(j)\n",
        "    return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "GTcc_OewDYJ4"
      },
      "outputs": [],
      "source": [
        "contexts = contextMaking(set_rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hjmdnx0Gr8D",
        "outputId": "cb120cdf-0633-4b92-ab08-de28bdbb5c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rules {<__main__.Rule object at 0x0000016CABAA2710>}\n",
            "rules {<__main__.Rule object at 0x0000016CABAA0C50>, <__main__.Rule object at 0x0000016CABAA1A50>}\n",
            "rules {<__main__.Rule object at 0x0000016CAA50F1D0>}\n",
            "rules {<__main__.Rule object at 0x0000016CABAA0F50>}\n"
          ]
        }
      ],
      "source": [
        "for c in contexts:\n",
        "  rules = c.getContextExistentialRules()\n",
        "  print(\"rules\", rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def partition(facts, negative_rule):\n",
        "  matched_facts_set = set()\n",
        "  result = []\n",
        "  for i in negative_rule:\n",
        "    matched_facts = []\n",
        "    predicate = i.getRuleBodyPredicates()\n",
        "    for j in facts:\n",
        "      terms = set(j.getFactTerms())\n",
        "      res = terms.intersection(set(predicate))\n",
        "      if res != 0:                          # if intersection is not empty\n",
        "        result.append(res)\n",
        "        matched_facts.append(j)\n",
        "    if len(matched_facts) != 0:                          #if intersection is not empty make new facts.\n",
        "        pfact = Fact(i.getRuleID())\n",
        "        for i in matched_facts:\n",
        "            for key, val in i.getFacts().items():\n",
        "                pfact.addFacts(key, val)\n",
        "                pfact.addFactTerms(key)\n",
        "                pfact.addFactConstant(val)\n",
        "        if pfact in matched_facts_set:\n",
        "          continue\n",
        "        else:\n",
        "          matched_facts_set.add(pfact)\n",
        "    return matched_facts_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{<__main__.Fact at 0x16cababa990>}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partition(set_facts, negative_rules_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "s0Qclm67Ci5_"
      },
      "outputs": [],
      "source": [
        "def fact_Partition(facts, context):\n",
        "    set_Partition_Fact = set()\n",
        "    for c in context:\n",
        "        label = set(c.getContextLabel())\n",
        "        matched_facts = []\n",
        "        for j in facts:\n",
        "            if j is not None:\n",
        "                terms = j.getFactTerms()\n",
        "                res = set(terms).intersection(label)\n",
        "                if res:  # Intersection is not empty\n",
        "                    matched_facts.append(j)\n",
        "        if matched_facts:\n",
        "            pfact = Fact(c.getContextID())\n",
        "            for i in matched_facts:\n",
        "                for key, val in i.getFacts().items():\n",
        "                    pfact.addFacts(key, val)\n",
        "                    pfact.addFactTerms(key)\n",
        "                    pfact.addFactConstant(val)\n",
        "            if pfact not in set_Partition_Fact:\n",
        "                set_Partition_Fact.add(pfact)\n",
        "    return set_Partition_Fact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm7Ff67dJ6IU",
        "outputId": "dcf7db5b-0d71-4a86-87af-f159d540b2e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{<__main__.Fact at 0x16cab912950>}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fact_Partition(set_facts, contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xKrfzx8KBKg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "uMnuy9kgCqN6"
      },
      "outputs": [],
      "source": [
        "def find_homomorphism(rule, fact):\n",
        "    substituation_dict = {}\n",
        "    rule_values = rule.getRuleExistentialVariables()           # take the values of the rules variables\n",
        "    rule_body = rule.getRuleBodyPredicates()                    # take the rule body predicates\n",
        "    #print(\"rule body\", rule_body)\n",
        "    if fact is not None:\n",
        "      fact_body = fact.getFacts()                                # get the fact dictionary\n",
        "      #print(\"list of facts\", list(fact_body.keys()))\n",
        "      for p in rule_body:                                # for predicate in the rule body check if it exist in the list of predicates of the facts\n",
        "          if p in list(fact_body.keys()):\n",
        "              substituation_dict[rule_values[p]] = fact_body[p]\n",
        "          else:\n",
        "              return None\n",
        "    return substituation_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQK2kc9CDDMC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WD9ViDV81fLb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK9c6V1GER0I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Nwa4m2qrNCG6"
      },
      "outputs": [],
      "source": [
        "### derive Method for Anomaly detection\n",
        "\n",
        "import random\n",
        "\n",
        "def derive_method(rule, fact):\n",
        "    derived_result = []\n",
        "    der = {}\n",
        "    random_dict = {}\n",
        "    fresh_variables = ['X', 'Y', 'Z']      # for those predicates whose value doesn't exist in the substituation set NEED TO IMPROVE\n",
        "    mapping = find_homomorphism(rule, fact)  # calling the function of homomorphism\n",
        "    #print(\"mapping\", mapping)\n",
        "    conclusion_predicates = rule.getRuleExistentialVariables().keys()   #get conclusion predicates\n",
        "    if mapping is not None:\n",
        "        print(\"mapping\", mapping)\n",
        "        for key, val in rule.getRuleConclusionVariables().items():      #if the mapping is not empty, get the keys and values\n",
        "            #for k,v in mapping.items():\n",
        "            if isinstance(val, tuple):                           # for the case when we have tuples as a value\n",
        "                new_list = []\n",
        "                for i in val:\n",
        "                    if i in mapping.keys():\n",
        "                        new_list.append(mapping[i])\n",
        "                    else:\n",
        "#                             if i in list(random_dict.copy().keys()):\n",
        "#                                 new_list.append(random_dict[i])\n",
        "#                             else:\n",
        "#                                 random_val = random.choice(fresh_variables)\n",
        "#                                 random_dict[i] = random_val\n",
        "#                                 new_list.append(random_val)\n",
        "                        if len(random_dict.copy()) == 0:\n",
        "                            random_val = random.choice(fresh_variables)          # assigning the new fresh values\n",
        "                            random_dict[i] = random_val\n",
        "                            new_list.append(random_val)                    # putting the values in the list to avoid the repeatition\n",
        "                        else:\n",
        "                            for t in random_dict.copy().keys():\n",
        "                                if i == t:\n",
        "                                    new_list.append(random_dict[t])\n",
        "                                    break\n",
        "                                else:\n",
        "                                    random_val = random.choice(fresh_variables)\n",
        "                                    random_dict[i] = random_val\n",
        "                                    new_list.append(random_val)\n",
        "                der[key] = new_list                          # assigning the list to the key\n",
        "                derived_result.append(der.copy())\n",
        "            else:\n",
        "                if val in mapping.keys():\n",
        "                    der[key] = mapping[val]\n",
        "                    derived_result.append(der.copy())\n",
        "                else:\n",
        "                    if len(random_dict.copy()) == 0:\n",
        "                        random_val = random.choice(fresh_variables)          # assigning the new fresh values\n",
        "                        random_dict[val] = random_val\n",
        "                        der[key] = random_val\n",
        "                        derived_result.append(der.copy())\n",
        "                    else:\n",
        "                        random_val = random.choice(fresh_variables)\n",
        "                        random_dict[key] = random_val\n",
        "                        der[key] = random_val\n",
        "                        derived_result.append(der.copy())\n",
        "    else:\n",
        "        return None\n",
        "    return derived_result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iWXmfC8ZGY6T"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "LXcFEb4HNIPo"
      },
      "outputs": [],
      "source": [
        "### context derive methond for anomaly detection\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "def context_make_derivation(context, fact):\n",
        "\n",
        "    result = []\n",
        "    new_factList = []\n",
        "    for r in set_rules:\n",
        "      res = derive_method(r, fact)\n",
        "      if res is not None:                             # if derivation is not empty\n",
        "          if res in result:                           # if the res is already existing or derived in pervisous derivation\n",
        "              break\n",
        "          else:\n",
        "              result.append(res)                      # append the derived result in list\n",
        "              new_fact = Fact(len(set_facts)+1)            # create new fact\n",
        "              for i in res:\n",
        "                  for key, val in i.items():            # make new derived facts and added to the set of facts\n",
        "                      new_fact.addFacts(key, val)\n",
        "                      new_fact.addFactTerms(key)\n",
        "                      new_fact.addFactConstant(val)\n",
        "                  new_factList.append(new_fact)\n",
        "    return new_factList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "teHN-G3-Tr36"
      },
      "outputs": [],
      "source": [
        "def context_conclusion(context)-> list:\n",
        "  list_conclusions = []\n",
        "  for r in context.getContextExistentialRules():\n",
        "    conclusion_rule = r.getRuleConclusions()\n",
        "    list_conclusions.append(conclusion_rule)\n",
        "  return list_conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv95cUzVnt0j",
        "outputId": "8936545c-dae7-4afe-c824-0bfb2af360b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Animal']\n",
            "['hasPart_Hair']\n"
          ]
        }
      ],
      "source": [
        "for f in set_facts:\n",
        "  print(f.getFactTerms())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "6qY1c7-oEpUI"
      },
      "outputs": [],
      "source": [
        "# def anomaly_detection(rules, facts, context, negative_rule):\n",
        "#   k = 0           ## number of derivation\n",
        "#   start = time.perf_counter()\n",
        "#   pervious_result = []\n",
        "#   current_result = []\n",
        "#   while True:\n",
        "#     k+=1\n",
        "#     matching_context = []\n",
        "#     negative_predicates = []\n",
        "#     partition = fact_Partition(facts, context)\n",
        "#     if len(negative_rule) != 0:\n",
        "#       for i in negative_rule:\n",
        "#         #print(\"rule predicates\", i.getRuleBodyPredicates())\n",
        "#         for f in facts:\n",
        "#           #print(\"fact terms\", f.getFactTerms())\n",
        "#           # should call mapping instead\n",
        "#           maping = find_homomorphism(i, f)\n",
        "#           #print(maping)\n",
        "#           if maping is not None:\n",
        "#             print(\"alert!!!!! Attack Detected, attack caused due to\", i.getRuleID(), i.getRuleBodyPredicates())\n",
        "#             end = time.perf_counter()\n",
        "#             process_time = end - start\n",
        "#             print(\"processing time\", process_time)\n",
        "#             return\n",
        "#           else:\n",
        "#             p = i.getRuleBodyPredicates()\n",
        "#             negative_predicates.append(p)\n",
        "#     else:\n",
        "#       print(\"no negative rules found\")\n",
        "#       end = time.perf_counter()\n",
        "#       process_time = end - start\n",
        "#       print(\"processing time\", process_time)\n",
        "#       return\n",
        "#     for c in context:\n",
        "#       list_context_conclusion = context_conclusion(c)\n",
        "#       # putting the values in one list\n",
        "#       flattened_list = [item for sublist in list_context_conclusion for item in sublist]\n",
        "#       #print(\"list of conclusions\", list_context_conclusion)\n",
        "#       for p in negative_predicates:\n",
        "#         #print(\"negative Predicate is\", p)\n",
        "#         common_elements = set(flattened_list).intersection(p)\n",
        "#         if len(common_elements) == 0:\n",
        "#           continue\n",
        "#         else:\n",
        "#           #print(\"here\")\n",
        "#           for f in partition:\n",
        "#             if c.getContextID() == f.getFactId():\n",
        "#               derivition = context_make_derivation(c, f)\n",
        "#               #print(\"new fact derived\", derivition)\n",
        "#               if derivition is not None:\n",
        "#                current_result = derivition\n",
        "#     if pervious_result is not None and pervious_result == current_result:\n",
        "#       print(\"no new facts derived\")\n",
        "#       end = time.perf_counter()\n",
        "#       process_time = end - start\n",
        "#       print(\"processing time\", process_time)\n",
        "#       return\n",
        "#     else:\n",
        "#       for i in current_result:\n",
        "#         facts.add(i)\n",
        "#       pervious_result = current_result\n",
        "#   end = time.perf_counter()\n",
        "#   process_time = end - start\n",
        "#   print(\"processing time\", process_time)\n",
        "\n",
        "#   return facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "def anomaly_Detection(rules, facts, context, negative_rule):\n",
        "  k = 0           ## number of derivation\n",
        "  start = time.perf_counter()\n",
        "  pervious_result = []\n",
        "  current_result = []\n",
        "  while True:\n",
        "    k+=1\n",
        "    matching_context = []\n",
        "    negative_predicates = []\n",
        "    partition_context = fact_Partition(facts, context)\n",
        "    if len(negative_rule) != 0:\n",
        "      partition_negative = partition(facts, negative_rule)\n",
        "      for r in negative_rule:\n",
        "        for f in partition_negative:\n",
        "          result = derive_method(r, f)\n",
        "          print(result)\n",
        "          if result is not None:\n",
        "            for i in result:\n",
        "              if 'alert' in i.keys():\n",
        "                print(\"alert!!!!! Attack Detected, attack caused due to\", r.getRuleID(), r.getRuleBodyPredicates())\n",
        "                end = time.perf_counter()\n",
        "                process_time = end - start\n",
        "                print(\"processing time\", process_time)\n",
        "                return\n",
        "          else:\n",
        "            p = r.getRuleBodyPredicates()\n",
        "            negative_predicates.append(p)\n",
        "    else:\n",
        "      print(\"no negative rules found\")\n",
        "      end = time.perf_counter()\n",
        "      process_time = end - start\n",
        "      print(\"processing time\", process_time)\n",
        "      return\n",
        "    for c in context:\n",
        "      print(\"here\")\n",
        "      list_context_conclusion = context_conclusion(c)\n",
        "      # putting the values in one list\n",
        "      flattened_list = [item for sublist in list_context_conclusion for item in sublist]\n",
        "      #print(\"list of conclusions\", list_context_conclusion)\n",
        "      for p in negative_predicates:\n",
        "        #print(\"negative Predicate is\", p)\n",
        "        common_elements = set(flattened_list).intersection(p)\n",
        "        if len(common_elements) == 0:\n",
        "          continue\n",
        "        else:\n",
        "          print(\"here\")\n",
        "          for f in partition_context:\n",
        "            if c.getContextID() == f.getFactId():\n",
        "              derivition = context_make_derivation(c, f)\n",
        "              #print(\"new fact derived\", derivition)\n",
        "              if derivition is not None:\n",
        "                if len(derivition) == 0:\n",
        "                  continue\n",
        "                else:\n",
        "                  current_result.append(derivition)\n",
        "              else:\n",
        "                print(\"nothing derived\")\n",
        "                return\n",
        "    print(\"current derivation list is\", current_result)\n",
        "    print(\"previous derivation list is\", pervious_result)\n",
        "    if pervious_result is not None and pervious_result == current_result:\n",
        "      print(\"no new facts derived\")\n",
        "      end = time.perf_counter()\n",
        "      process_time = end - start\n",
        "      print(\"processing time\", process_time)\n",
        "      return\n",
        "    else:\n",
        "      for i in current_result:\n",
        "        for j in i:\n",
        "          facts.add(j)\n",
        "      pervious_result = current_result\n",
        "  end = time.perf_counter()\n",
        "  process_time = end - start\n",
        "  print(\"processing time\", process_time)\n",
        "\n",
        "  return facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGn6Ig5aMYQc",
        "outputId": "397687ba-ce29-4224-cee7-106796216fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "here\n",
            "here\n",
            "here\n",
            "mapping {'x': ['Mice', 'Dogs', 'Cats', 'Camels']}\n",
            "here\n",
            "here\n",
            "current derivation list is [[<__main__.Fact object at 0x0000016CAB9FC8D0>]]\n",
            "previous derivation list is []\n",
            "mapping {'x': ['Mice', 'Dogs', 'Cats', 'Camels']}\n",
            "[{'alert': ['Mice', 'Dogs', 'Cats', 'Camels']}]\n",
            "alert!!!!! Attack Detected, attack caused due to 4 ['Mammal']\n",
            "processing time 0.00023170001804828644\n"
          ]
        }
      ],
      "source": [
        "anomaly_Detection(set_rules, set_facts, contexts, negative_rules_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9JGHTOtVK7B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
